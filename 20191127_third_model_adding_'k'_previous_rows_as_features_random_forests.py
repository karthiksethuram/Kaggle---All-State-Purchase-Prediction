# -*- coding: utf-8 -*-
"""20191127_Third_Model_Adding_'K'_Previous_Rows_as_Features_Random_forests.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p3Hmmd3n1ndmaVsjsgyvNfS9ydEGkEf6
"""

import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
from sklearn.ensemble import RandomForestClassifier
from scipy import stats
import xgboost as xgb

"""### Data Preparation"""

train=pd.read_csv("train.csv")
test=pd.read_csv("test_v2.csv")
print(train.shape)
print(test.shape)

frames = [train, test]
my_data = pd.concat(frames,keys=['train', 'test'])
print(my_data.shape)


my_data['location'] = my_data['location'].fillna(0)
my_data['C_previous'] = my_data['C_previous'].fillna(99)
my_data['duration_previous'] = my_data['duration_previous'].fillna(99)
my_data['car_value'] = my_data['car_value'].fillna(99)

my_data.isnull().sum(axis = 0)
my_data= my_data.dropna(axis='columns')
my_data.isnull().sum(axis = 0)

def one_hot(df, cols):
    for col in cols:
        df[col] = df[col].astype('category')
    df=pd.concat([df,pd.get_dummies(df[cols])], axis=1)
    df.drop(cols, axis=1, inplace=True)
    return df
        
def time_convert(df):
    df['time'] = df['time'].apply(lambda x: (int(x[:2]) * 60) + int(x[3:]))
    df['time_sin'] = np.sin((df['time'] * np.pi) / 1800)
    df['time_cos'] = np.cos((df['time'] * np.pi) / 1800)
    df = df.drop(['time'], axis=1)
    return df

cat_cols = ['shopping_pt','day', 'state',
       'group_size', 'homeowner', 'car_age','car_value', 'age_oldest', 'age_youngest',
       'married_couple','C_previous','duration_previous']
my_data = one_hot(my_data,cat_cols)
my_data = time_convert(my_data)

#Split data back in to train & Test

my_train=my_data.loc['train']
my_test=my_data.loc['test']
print(my_train.shape)
print(my_test.shape)

#Getting the purchased Data as columns in my train
purchased_data=my_train.loc[my_train.groupby('customer_ID').record_type.idxmax()][['customer_ID','A','B','C','D','E','F','G']]
purchased_data=purchased_data.rename(columns={"A": "A_purchased","B": "B_purchased","C": "C_purchased","D": "D_purchased","E": "E_purchased","F": "F_purchased","G": "G_purchased",})
# my_train=my_train.merge(purchased_data, left_on='customer_ID', right_on='customer_ID', how='left')

#Getting the previous quotes as columns

# For Train Data

for i in range(1,3):
    my_train['A_previous_{}'.format(i)]=my_train['A'].shift(i)
    my_train['B_previous_{}'.format(i)]=my_train['B'].shift(i)
    my_train['C_previous_{}'.format(i)]=my_train['C'].shift(i)
    my_train['D_previous_{}'.format(i)]=my_train['D'].shift(i)
    my_train['E_previous_{}'.format(i)]=my_train['E'].shift(i)
    my_train['F_previous_{}'.format(i)]=my_train['F'].shift(i)
    my_train['G_previous_{}'.format(i)]=my_train['G'].shift(i)
    
# For Test Data

for i in range(1,3):
    my_test['A_previous_{}'.format(i)]=my_test['A'].shift(i)
    my_test['B_previous_{}'.format(i)]=my_test['B'].shift(i)
    my_test['C_previous_{}'.format(i)]=my_test['C'].shift(i)
    my_test['D_previous_{}'.format(i)]=my_test['D'].shift(i)
    my_test['E_previous_{}'.format(i)]=my_test['E'].shift(i)
    my_test['F_previous_{}'.format(i)]=my_test['F'].shift(i)
    my_test['G_previous_{}'.format(i)]=my_test['G'].shift(i)

#Getting the Last row alone for each column
my_train = my_train[my_train['record_type'] == 1]
my_test=my_test.groupby('customer_ID').last()
print(my_train.shape)
print(my_test.shape)

for i in range(1,3):
    my_test['A_previous_{}'.format(i)]=my_test['A_previous_{}'.format(i)].fillna(99)
    my_test['B_previous_{}'.format(i)]=my_test['B_previous_{}'.format(i)].fillna(99)
    my_test['C_previous_{}'.format(i)]=my_test['C_previous_{}'.format(i)].fillna(99)
    my_test['D_previous_{}'.format(i)]=my_test['D_previous_{}'.format(i)].fillna(99)
    my_test['E_previous_{}'.format(i)]=my_test['E_previous_{}'.format(i)].fillna(99)
    my_test['F_previous_{}'.format(i)]=my_test['F_previous_{}'.format(i)].fillna(99)
    my_test['G_previous_{}'.format(i)]=my_test['G_previous_{}'.format(i)].fillna(99)
    
for i in range(1,3):
    my_train['A_previous_{}'.format(i)]=my_train['A_previous_{}'.format(i)].fillna(99)
    my_train['B_previous_{}'.format(i)]=my_train['B_previous_{}'.format(i)].fillna(99)
    my_train['C_previous_{}'.format(i)]=my_train['C_previous_{}'.format(i)].fillna(99)
    my_train['D_previous_{}'.format(i)]=my_train['D_previous_{}'.format(i)].fillna(99)
    my_train['E_previous_{}'.format(i)]=my_train['E_previous_{}'.format(i)].fillna(99)
    my_train['F_previous_{}'.format(i)]=my_train['F_previous_{}'.format(i)].fillna(99)
    my_train['G_previous_{}'.format(i)]=my_train['G_previous_{}'.format(i)].fillna(99)

my_test['customer_ID']=my_test.index
my_test=my_test.reset_index(drop=True)

#One hot encoding 
#options = ['A','B','C','D','E','F','G','A_previous_1','A_previous_2','A_previous_3','B_previous_1','B_previous_2','B_previous_3','C_previous_1','C_previous_2','C_previous_3','D_previous_1','D_previous_2','D_previous_3','E_previous_1','E_previous_2','E_previous_3','F_previous_1','F_previous_2','F_previous_3','G_previous_1','G_previous_2','G_previous_3']
options = ['A','B','C','D','E','F','G','A_previous_1','A_previous_2','B_previous_1','B_previous_2','C_previous_1','C_previous_2','D_previous_1','D_previous_2','E_previous_1','E_previous_2','F_previous_1','F_previous_2','G_previous_1','G_previous_2']


frames = [my_train, my_test]
my_data = pd.concat(frames,keys=['train', 'test'])
print(my_data.shape)
my_data = one_hot(my_data,options)

my_train=my_data.loc['train']
my_test=my_data.loc['test']
print(my_train.shape)
print(my_test.shape)

my_train=my_train.merge(purchased_data, left_on='customer_ID', right_on='customer_ID', how='left')

"""XGB Model Parameters"""

MAX_DEPTH=7
NTREES=100
ALPHA=0.1

"""### Prediction of G"""

#splitting my train data in to train & validation
y = my_train['G_purchased']
X = my_train.copy()
X.drop(['record_type','customer_ID','A_purchased','B_purchased','C_purchased',
        'D_purchased','E_purchased','F_purchased','G_purchased'], axis=1, inplace=True)

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=101, stratify=y)
print("Training data size", X_train.shape)
print("validation data size", X_val.shape)
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_val, label=y_val)

#Create a Gaussian Classifier
clf = xgb.XGBClassifier(max_depth=MAX_DEPTH, n_estimators=NTREES, learning_rate=ALPHA, objective="multi:softprob")

#Train the model using the training sets y_pred=clf.predict(X_val)
clf.fit(X_train,y_train)
y_pred=clf.predict(X_val)
print("Accuracy:",metrics.accuracy_score(y_val, y_pred))

#Applying the model on test Data
G_pred=pd.DataFrame(my_test[['customer_ID']])
my_test_G=my_test.drop(['record_type','customer_ID'], axis=1)

clf=RandomForestClassifier(n_estimators=100)
clf.fit(X,y)
G_pred['G_predicted']=clf.predict(my_test_G)

"""### Prediction of C & D using predicted C"""

#MODEL FOR C

#splitting my train data in to train & validation
y = my_train['C_purchased']
X = my_train.copy()
X.drop(['record_type','customer_ID','A_purchased','B_purchased','C_purchased',
        'D_purchased','E_purchased','F_purchased','G_purchased'], axis=1, inplace=True)

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=101)
print("Training data size", X_train.shape)
print("validation data size", X_val.shape)

#Create a Gaussian Classifier
clf=RandomForestClassifier(n_estimators=100)

#Train the model using the training sets y_pred=clf.predict(X_test)
clf.fit(X_train,y_train)
y_pred=clf.predict(X_val)
print("Accuracy:",metrics.accuracy_score(y_val, y_pred))

#Applying the model on test Data
C_pred=pd.DataFrame(my_test[['customer_ID']])
my_test_C=my_test.drop(['record_type','customer_ID'], axis=1)

clf=RandomForestClassifier(n_estimators=100)
clf.fit(X,y)
C_pred['C_predicted']=clf.predict(my_test_C)

#MODEL FOR D

#splitting my train data in to train & validation
y = my_train['D_purchased']
X = my_train.copy()
X.drop(['record_type','customer_ID','A_purchased','B_purchased',
        'D_purchased','E_purchased','F_purchased','G_purchased'], axis=1, inplace=True)

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=101)
print("Training data size", X_train.shape)
print("validation data size", X_val.shape)

#Create a Gaussian Classifier
clf=RandomForestClassifier(n_estimators=100)

#Train the model using the training sets y_pred=clf.predict(X_test)
clf.fit(X_train,y_train)
y_pred=clf.predict(X_val)
print("Accuracy:",metrics.accuracy_score(y_val, y_pred))

#Applying the model on test Data
my_test_D=my_test.copy()
D_pred=pd.DataFrame(my_test[['customer_ID']])
my_test_D=my_test_D.merge(C_pred, left_on='customer_ID', right_on='customer_ID', how='left')
my_test_D=my_test_D.drop(['record_type','customer_ID'], axis=1)

clf=RandomForestClassifier(n_estimators=100)
clf.fit(X,y)
D_pred['D_predicted']=clf.predict(my_test_D)

"""### Prediction of A, Then E & F Using A-Predicted"""

#MODEL FOR A

#splitting my train data in to train & validation
y = my_train['A_purchased']
X = my_train.copy()
X.drop(['record_type','customer_ID','A_purchased','B_purchased','C_purchased',
        'D_purchased','E_purchased','F_purchased','G_purchased'], axis=1, inplace=True)

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=101)
print("Training data size", X_train.shape)
print("validation data size", X_val.shape)

#Create a Gaussian Classifier
clf=RandomForestClassifier(n_estimators=100)

#Train the model using the training sets y_pred=clf.predict(X_test)
clf.fit(X_train,y_train)
y_pred=clf.predict(X_val)
print("Accuracy:",metrics.accuracy_score(y_val, y_pred))

#Applying the model on test Data
A_pred=pd.DataFrame(my_test[['customer_ID']])
my_test_A=my_test.drop(['record_type','customer_ID'], axis=1)

clf=RandomForestClassifier(n_estimators=100)
clf.fit(X,y)
A_pred['A_predicted']=clf.predict(my_test_A)

#MODEL FOR F   - USING A PREDICTED

#splitting my train data in to train & validation
y = my_train['F_purchased']
X = my_train.copy()
X.drop(['record_type','customer_ID','B_purchased','C_purchased',
        'D_purchased','E_purchased','F_purchased','G_purchased'], axis=1, inplace=True)

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=101)
print("Training data size", X_train.shape)
print("validation data size", X_val.shape)

#Create a Gaussian Classifier
clf=RandomForestClassifier(n_estimators=100)

#Train the model using the training sets y_pred=clf.predict(X_test)
clf.fit(X_train,y_train)
y_pred=clf.predict(X_val)
print("Accuracy:",metrics.accuracy_score(y_val, y_pred))

#Applying the model on test Data
my_test_F=my_test.copy()
F_pred=pd.DataFrame(my_test[['customer_ID']])
my_test_F=my_test_F.merge(A_pred, left_on='customer_ID', right_on='customer_ID', how='left')
my_test_F=my_test_F.drop(['record_type','customer_ID'], axis=1)

clf=RandomForestClassifier(n_estimators=100)
clf.fit(X,y)
F_pred['F_predicted']=clf.predict(my_test_F)



#MODEL FOR E   - USING A PREDICTED

#splitting my train data in to train & validation
y = my_train['E_purchased']
X = my_train.copy()
X.drop(['record_type','customer_ID','B_purchased','C_purchased',
        'D_purchased','E_purchased','F_purchased','G_purchased'], axis=1, inplace=True)

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=101)
print("Training data size", X_train.shape)
print("validation data size", X_val.shape)

#Create a Gaussian Classifier
clf=RandomForestClassifier(n_estimators=100)

#Train the model using the training sets y_pred=clf.predict(X_test)
clf.fit(X_train,y_train)
y_pred=clf.predict(X_val)
print("Accuracy:",metrics.accuracy_score(y_val, y_pred))

#Applying the model on test Data - Joining A predicted to be used in the test data
my_test_E=my_test.copy()
E_pred=pd.DataFrame(my_test[['customer_ID']])
my_test_E=my_test_E.merge(A_pred, left_on='customer_ID', right_on='customer_ID', how='left')
my_test_E=my_test_E.drop(['record_type','customer_ID'], axis=1)

clf=RandomForestClassifier(n_estimators=100)
clf.fit(X,y)
E_pred['E_predicted']=clf.predict(my_test_E)



"""### Prediction of B using E-Predicted"""

#MODEL FOR B

#splitting my train data in to train & validation
y = my_train['B_purchased']
X = my_train.copy()
X.drop(['record_type','customer_ID','A_purchased','B_purchased','C_purchased',
        'D_purchased','F_purchased','G_purchased'], axis=1, inplace=True)

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=101)
print("Training data size", X_train.shape)
print("validation data size", X_val.shape)

#Create a Gaussian Classifier
clf=RandomForestClassifier(n_estimators=100)

#Train the model using the training sets y_pred=clf.predict(X_test)
clf.fit(X_train,y_train)
y_pred=clf.predict(X_val)
print("Accuracy:",metrics.accuracy_score(y_val, y_pred))

#Applying the model on test Data
my_test_B=my_test.copy()
B_pred=pd.DataFrame(my_test[['customer_ID']])
my_test_B=my_test_B.merge(E_pred, left_on='customer_ID', right_on='customer_ID', how='left')
my_test_B=my_test_B.drop(['record_type','customer_ID'], axis=1)

#Applying the model on test Data

clf.fit(X_train,y_train)
y_pred=clf.predict(X_val)
B_pred['B_predicted']=clf.predict(my_test_B)



# final_predictions_df=A_predicted_mode.merge(B_predicted_mode,on='customer_ID').merge(C_predicted_mode,on='customer_ID').merge(D_predicted_mode,on='customer_ID').merge(E_predicted_mode,on='customer_ID').merge(F_predicted_mode,on='customer_ID').merge(G_predicted_mode,on='customer_ID')

final_predictions_df=A_pred.merge(B_pred,on='customer_ID').merge(C_pred,on='customer_ID').merge(D_pred,on='customer_ID').merge(E_pred,on='customer_ID').merge(F_pred,on='customer_ID').merge(G_pred,on='customer_ID')

for C in final_predictions_df.columns:
    final_predictions_df[C]=final_predictions_df[C].astype(str)
final_predictions_df['plan']=final_predictions_df['A_predicted'] + final_predictions_df['B_predicted'] + final_predictions_df['C_predicted'] + final_predictions_df['D_predicted'] + final_predictions_df['E_predicted'] + final_predictions_df['F_predicted'] + final_predictions_df['G_predicted']

final_predictions_df=final_predictions_df[['customer_ID','plan']]

final_predictions_df.to_csv(r'Random_Forest_result.csv', index=False)



final_predictions_df

