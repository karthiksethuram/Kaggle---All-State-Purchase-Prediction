# -*- coding: utf-8 -*-
"""Correlation Analysis

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XrY0lAnq8qrEfVvfMOIpqU3_F7Pp3Axi
"""

import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
from sklearn.ensemble import RandomForestClassifier
from scipy import stats
import itertools
import collections
import operator

train=pd.read_csv("train.csv")
test=pd.read_csv("test_v2.csv")
print(train.shape)
print(test.shape)

frames = [train, test]
my_data = pd.concat(frames,keys=['train', 'test'])
print(my_data.shape)

train.columns

#Filter for rows with Response =1
my_train = train[train.record_type==1]

#looking at pearson's correlation - This doesn't make a lot of sense for Categorical Variables. Just giving a try to see how it looks
train_policy= my_train[['A','B','C','D','E','F','G']]
corr = train_policy.corr()
corr.style.background_gradient(cmap='coolwarm')

"""Compute Cramer's V for all the Quote Combination from the Responders data Alone"""

cols=['A','B','C','D','E','F','G']
s=[(x,y) for x,y in itertools.combinations(cols,2)]

def cramers_corrected_stat(confusion_matrix):
    """ calculate Cramers V statistic for categorial-categorial association.
        uses correction from Bergsma and Wicher, 
        Journal of the Korean Statistical Society 42 (2013): 323-328
    """
    chi2 = stats.chi2_contingency(confusion_matrix)[0]
    n = confusion_matrix.sum().sum()
    phi2 = chi2/n
    r,k = confusion_matrix.shape
    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))    
    rcorr = r - ((r-1)**2)/(n-1)
    kcorr = k - ((k-1)**2)/(n-1)
    return np.sqrt(phi2corr / min( (kcorr-1), (rcorr-1)))

mat_dic={}
cramers_v={}
for i in range(len(s)):
      mat_dic[s[i][0]+s[i][1]] = pd.crosstab(my_train[s[i][0]], my_train[s[i][1]])
      cramers_v[s[i][0]+s[i][1]] = cramers_corrected_stat( mat_dic[s[i][0]+s[i][1]] )
cramers_v = collections.OrderedDict(cramers_v)

cramers_v
sorted(cramers_v.items(), key=operator.itemgetter(1),reverse=True)

# We can infer from the above correaltion Values that AEF, CD and BE are the ones which are most correlated

cramers_v['AB']

