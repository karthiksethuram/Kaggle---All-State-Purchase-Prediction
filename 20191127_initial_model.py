# -*- coding: utf-8 -*-
"""20191127_Initial_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fV6Ouo2Y8S7y25vYC9jva9aogRS-I1Wb
"""

import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
from sklearn.ensemble import RandomForestClassifier

"""### Baseline Submission"""

test=pd.read_csv("C:/Users/karth/Documents/Kaggle/Purchase Prediction/test_v2.csv")
test.head(5)

print(test.size)
result=test.sort_values(by=['day','time']).groupby('customer_ID').tail(1)
result=result[['customer_ID','A','B','C','D','E','F','G']]
result.head()

for C in result.columns:
    result[C]=result[C].astype(str)
result.head()
result['plan']=result['A'] + result['B']+ result['C']+ result['D']+ result['E']+ result['F']+ result['G']
result=result[['customer_ID','plan']]
result.head()

result.to_csv('baseline.csv')



"""### Data Preparation"""

train=pd.read_csv("C:/Users/karth/Documents/Kaggle/Purchase Prediction/train.csv")
test=pd.read_csv("C:/Users/karth/Documents/Kaggle/Purchase Prediction/test_v2.csv")
print(train.shape)
print(test.shape)

frames = [train, test]
my_data = pd.concat(frames,keys=['train', 'test'])
print(my_data.shape)

my_data['location'] = my_data['location'].fillna(0)
my_data['C_previous'] = my_data['C_previous'].fillna(99)
my_data['duration_previous'] = my_data['duration_previous'].fillna(99)
my_data['car_value'] = my_data['car_value'].fillna(99)

my_data= my_data.dropna(axis='columns')
my_data.isnull().sum(axis = 0)

def one_hot(df, cols):
    for col in cols:
        df[col] = df[col].astype('category')
    df=pd.concat([df,pd.get_dummies(df[cols])], axis=1)
    df.drop(cols, axis=1, inplace=True)
    return df
        
def time_convert(df):
    df['time'] = df['time'].apply(lambda x: (int(x[:2]) * 60) + int(x[3:]))
    df['time_sin'] = np.sin((df['time'] * np.pi) / 1800)
    df['time_cos'] = np.cos((df['time'] * np.pi) / 1800)
    df = df.drop(['time'], axis=1)
    return df

cat_cols = ['shopping_pt','day', 'state',
       'group_size', 'homeowner', 'car_age','car_value', 'age_oldest', 'age_youngest',
       'married_couple','C_previous','duration_previous','A','B','C','D','E','F','G']
my_data = one_hot(my_data,cat_cols)
my_data = time_convert(my_data)

#Split data back in to train & Test

my_train=my_data.loc['train']
my_test=my_data.loc['test']
print(my_train.shape)
print(my_test.shape)

my_train.columns

#splitting my train data in to train & validation
y = my_train['record_type']
X = my_train
X.drop(['record_type','customer_ID'], axis=1, inplace=True)


X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=101)
print("Training data size", X_train.shape)
print("validation data size", X_val.shape)

logreg = LogisticRegression()
logreg.fit(X_train, y_train)
y_pred_val=logreg.predict(X_val)
metrics.confusion_matrix(y_val,y_pred)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
print(classification_report(y_val,y_pred))
print(accuracy_score(y_val, y_pred))

### Predict test_y values and probabilities based on fitted logistic 

y_pred_val=logreg.predict(X_val)
y_pred_prob_val=logreg.predict_proba(X_val) 

from sklearn.metrics import precision_recall_curve
precision, recall, thresholds = precision_recall_curve(y_val, y_pred_prob_val[:,1]) 

#retrieve probability of being 1(in second column of probs_y)
pr_auc = metrics.auc(recall, precision)

plt.title("Precision-Recall vs Threshold Chart")
plt.plot(thresholds, precision[: -1], "b--", label="Precision")
plt.plot(thresholds, recall[: -1], "r--", label="Recall")
plt.ylabel("Precision, Recall")
plt.xlabel("Threshold")
plt.legend(loc="lower left")
plt.ylim([0,1])

#Changing Threshold of Logistic regression
mythreshold=0.1
y_pred_val = (y_pred_prob_val[:,1]>= mythreshold).astype(int)
print(accuracy_score(y_val, y_pred_val))

#Buidling model on entire data and predicting on Test data
logreg = LogisticRegression()
logreg.fit(X, y)

my_test_copy=my_test.drop(['record_type','customer_ID'], axis=1)
test_pred=logreg.predict_proba(my_test_copy)

y_pred_test = (test_pred[:,1]>= mythreshold).astype(int)

print(sum(y_pred_test))
print(test.customer_ID.unique().size)